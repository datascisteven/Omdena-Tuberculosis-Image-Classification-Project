{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import datetime\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import load_model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Dropout, Flatten, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, CSVLogger, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from utils import *\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9822 images belonging to 2 classes.\n",
      "Found 2456 images belonging to 2 classes.\n",
      "Found 3289 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# generating augmentations through ImageDataGenerator\n",
    "image_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "# assigning paths\n",
    "train_folder = 'data/Tuberculosis/augmented_sorted/train'\n",
    "val_folder = 'data/Tuberculosis/augmented_sorted/val'\n",
    "test_folder = 'data/Tuberculosis/augmented_sorted/test'\n",
    "\n",
    "train_generator = image_generator.flow_from_directory(train_folder, \n",
    "                                                      batch_size=16, \n",
    "                                                      shuffle=True, \n",
    "                                                      class_mode='binary',\n",
    "                                                      target_size=(224, 224),\n",
    "                                                      seed=42)\n",
    "\n",
    "val_generator = image_generator.flow_from_directory(val_folder,\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    batch_size = 16,\n",
    "                                                    shuffle=True,\n",
    "                                                    class_mode = 'binary',\n",
    "                                                    seed = 42)\n",
    "\n",
    "test_generator = image_generator.flow_from_directory(test_folder,\n",
    "                                                     target_size = (224, 224),\n",
    "                                                     batch_size = 1,\n",
    "                                                     class_mode = 'binary',\n",
    "                                                     shuffle=False, \n",
    "                                                     seed=42)\n",
    "\n",
    "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
    "STEP_SIZE_VALID = val_generator.n // val_generator.batch_size\n",
    "STEP_SIZE_TEST = test_generator.n // test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.38098147016900835, 1: 0.6190185298309917}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate class weights\n",
    "total_tb = len(os.listdir(os.path.join(train_folder, 'TB')))\n",
    "total_healthy = len(os.listdir(os.path.join(train_folder, 'Non-TB')))\n",
    "\n",
    "weight_for_0 = total_tb / (total_healthy + total_tb)\n",
    "weight_for_1 = total_healthy / (total_healthy + total_tb)\n",
    "\n",
    "class_weights = {0: weight_for_0, 1: weight_for_1}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the EfficientNetB4 model pre-trained on ImageNet data\n",
    "def create_model(input_shape):\n",
    "    base_model = EfficientNetB4(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False  # Freeze the pre-trained layers\n",
    "    \n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(units=128, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# save model\n",
    "model = create_model((224, 224, 3))\n",
    "\n",
    "# compile model\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.01),\n",
    "              metrics = ['accuracy', AUC(), AUC(curve='PR'), Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define callbacks\n",
    "# earlyStopping = EarlyStopping(monitor = 'val_loss', \n",
    "#                               verbose = 1, \n",
    "#                               mode = 'min', \n",
    "#                               patience = 4)\n",
    "lr_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                 patience = 3,\n",
    "                                 verbose = 1,\n",
    "                                 factor = 0.5,\n",
    "                                 min_lr = 0.00001)\n",
    "filepath = \"modeling/log_effnet/model.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "mcp_save = ModelCheckpoint(filepath, \n",
    "                           verbose = 1, \n",
    "                           monitor = 'val_loss', \n",
    "                           mode = 'min')\n",
    "csv_logger = CSVLogger('modeling/log_effnet/log.csv')\n",
    "log_dir = \"modeling/log_effnet/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_cb = TensorBoard(log_dir = log_dir,\n",
    "                             histogram_freq = 1,\n",
    "                             update_freq = 'batch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 02:23:16.082303: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - ETA: 0s - loss: 0.4727 - accuracy: 0.5760 - auc_2: 0.6009 - auc_3: 0.4862 - precision_1: 0.4551 - recall_1: 0.5713"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 02:25:23.511217: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to modeling/log_effnet/model.01-0.53.hdf5\n",
      "613/613 [==============================] - 169s 260ms/step - loss: 0.4727 - accuracy: 0.5760 - auc_2: 0.6009 - auc_3: 0.4862 - precision_1: 0.4551 - recall_1: 0.5713 - val_loss: 0.5297 - val_accuracy: 0.7774 - val_auc_2: 0.7752 - val_auc_3: 0.7814 - val_precision_1: 0.8836 - val_recall_1: 0.4797 - lr: 0.0100\n",
      "Epoch 2/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.3778 - accuracy: 0.6188 - auc_2: 0.6606 - auc_3: 0.5881 - precision_1: 0.4994 - recall_1: 0.6019\n",
      "Epoch 2: saving model to modeling/log_effnet/model.02-1.06.hdf5\n",
      "613/613 [==============================] - 153s 250ms/step - loss: 0.3778 - accuracy: 0.6188 - auc_2: 0.6606 - auc_3: 0.5881 - precision_1: 0.4994 - recall_1: 0.6019 - val_loss: 1.0554 - val_accuracy: 0.3787 - val_auc_2: 0.7755 - val_auc_3: 0.7814 - val_precision_1: 0.3796 - val_recall_1: 0.9936 - lr: 0.0100\n",
      "Epoch 3/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.4122 - accuracy: 0.6236 - auc_2: 0.6679 - auc_3: 0.5996 - precision_1: 0.5049 - recall_1: 0.6118\n",
      "Epoch 3: saving model to modeling/log_effnet/model.03-1.40.hdf5\n",
      "613/613 [==============================] - 154s 250ms/step - loss: 0.4122 - accuracy: 0.6236 - auc_2: 0.6679 - auc_3: 0.5996 - precision_1: 0.5049 - recall_1: 0.6118 - val_loss: 1.4016 - val_accuracy: 0.3799 - val_auc_2: 0.7735 - val_auc_3: 0.7780 - val_precision_1: 0.3802 - val_recall_1: 0.9979 - lr: 0.0100\n",
      "Epoch 4/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.4274 - accuracy: 0.6379 - auc_2: 0.6835 - auc_3: 0.6308 - precision_1: 0.5207 - recall_1: 0.6242\n",
      "Epoch 4: saving model to modeling/log_effnet/model.04-0.57.hdf5\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "613/613 [==============================] - 156s 255ms/step - loss: 0.4274 - accuracy: 0.6379 - auc_2: 0.6835 - auc_3: 0.6308 - precision_1: 0.5207 - recall_1: 0.6242 - val_loss: 0.5656 - val_accuracy: 0.7145 - val_auc_2: 0.7751 - val_auc_3: 0.7808 - val_precision_1: 0.6046 - val_recall_1: 0.7270 - lr: 0.0100\n",
      "Epoch 5/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.3155 - accuracy: 0.6743 - auc_2: 0.7210 - auc_3: 0.7064 - precision_1: 0.5656 - recall_1: 0.6276\n",
      "Epoch 5: saving model to modeling/log_effnet/model.05-0.85.hdf5\n",
      "613/613 [==============================] - 156s 253ms/step - loss: 0.3155 - accuracy: 0.6743 - auc_2: 0.7210 - auc_3: 0.7064 - precision_1: 0.5656 - recall_1: 0.6276 - val_loss: 0.8481 - val_accuracy: 0.4322 - val_auc_2: 0.7742 - val_auc_3: 0.7793 - val_precision_1: 0.3937 - val_recall_1: 0.9099 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.3358 - accuracy: 0.6668 - auc_2: 0.7137 - auc_3: 0.6860 - precision_1: 0.5560 - recall_1: 0.6255\n",
      "Epoch 6: saving model to modeling/log_effnet/model.06-0.53.hdf5\n",
      "613/613 [==============================] - 152s 248ms/step - loss: 0.3358 - accuracy: 0.6668 - auc_2: 0.7137 - auc_3: 0.6860 - precision_1: 0.5560 - recall_1: 0.6255 - val_loss: 0.5259 - val_accuracy: 0.7757 - val_auc_2: 0.7751 - val_auc_3: 0.7805 - val_precision_1: 0.9120 - val_recall_1: 0.4555 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.3383 - accuracy: 0.6640 - auc_2: 0.7134 - auc_3: 0.6954 - precision_1: 0.5523 - recall_1: 0.6278\n",
      "Epoch 7: saving model to modeling/log_effnet/model.07-1.09.hdf5\n",
      "\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "613/613 [==============================] - 172s 280ms/step - loss: 0.3383 - accuracy: 0.6640 - auc_2: 0.7134 - auc_3: 0.6954 - precision_1: 0.5523 - recall_1: 0.6278 - val_loss: 1.0870 - val_accuracy: 0.3750 - val_auc_2: 0.7756 - val_auc_3: 0.7801 - val_precision_1: 0.3758 - val_recall_1: 0.9657 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.2922 - accuracy: 0.6936 - auc_2: 0.7391 - auc_3: 0.7294 - precision_1: 0.5910 - recall_1: 0.6361\n",
      "Epoch 8: saving model to modeling/log_effnet/model.08-0.85.hdf5\n",
      "613/613 [==============================] - 166s 269ms/step - loss: 0.2922 - accuracy: 0.6936 - auc_2: 0.7391 - auc_3: 0.7294 - precision_1: 0.5910 - recall_1: 0.6361 - val_loss: 0.8531 - val_accuracy: 0.4281 - val_auc_2: 0.7742 - val_auc_3: 0.7791 - val_precision_1: 0.3923 - val_recall_1: 0.9121 - lr: 0.0025\n",
      "Epoch 9/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.2919 - accuracy: 0.6951 - auc_2: 0.7355 - auc_3: 0.7285 - precision_1: 0.5936 - recall_1: 0.6327\n",
      "Epoch 9: saving model to modeling/log_effnet/model.09-0.64.hdf5\n",
      "613/613 [==============================] - 163s 266ms/step - loss: 0.2919 - accuracy: 0.6951 - auc_2: 0.7355 - auc_3: 0.7285 - precision_1: 0.5936 - recall_1: 0.6327 - val_loss: 0.6443 - val_accuracy: 0.6017 - val_auc_2: 0.7743 - val_auc_3: 0.7800 - val_precision_1: 0.4862 - val_recall_1: 0.8122 - lr: 0.0025\n",
      "Epoch 10/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.2940 - accuracy: 0.6989 - auc_2: 0.7346 - auc_3: 0.7270 - precision_1: 0.5975 - recall_1: 0.6402\n",
      "Epoch 10: saving model to modeling/log_effnet/model.10-0.60.hdf5\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "613/613 [==============================] - 157s 254ms/step - loss: 0.2940 - accuracy: 0.6989 - auc_2: 0.7346 - auc_3: 0.7270 - precision_1: 0.5975 - recall_1: 0.6402 - val_loss: 0.6007 - val_accuracy: 0.6614 - val_auc_2: 0.7750 - val_auc_3: 0.7804 - val_precision_1: 0.5384 - val_recall_1: 0.7747 - lr: 0.0025\n",
      "Epoch 11/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.2760 - accuracy: 0.7117 - auc_2: 0.7493 - auc_3: 0.7430 - precision_1: 0.6182 - recall_1: 0.6366\n",
      "Epoch 11: saving model to modeling/log_effnet/model.11-0.57.hdf5\n",
      "613/613 [==============================] - 152s 248ms/step - loss: 0.2760 - accuracy: 0.7117 - auc_2: 0.7493 - auc_3: 0.7430 - precision_1: 0.6182 - recall_1: 0.6366 - val_loss: 0.5661 - val_accuracy: 0.7116 - val_auc_2: 0.7746 - val_auc_3: 0.7807 - val_precision_1: 0.6011 - val_recall_1: 0.7283 - lr: 0.0012\n",
      "Epoch 12/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.2766 - accuracy: 0.7098 - auc_2: 0.7411 - auc_3: 0.7412 - precision_1: 0.6167 - recall_1: 0.6250\n",
      "Epoch 12: saving model to modeling/log_effnet/model.12-0.51.hdf5\n",
      "613/613 [==============================] - 150s 245ms/step - loss: 0.2766 - accuracy: 0.7098 - auc_2: 0.7411 - auc_3: 0.7412 - precision_1: 0.6167 - recall_1: 0.6250 - val_loss: 0.5060 - val_accuracy: 0.7819 - val_auc_2: 0.7746 - val_auc_3: 0.7803 - val_precision_1: 0.8220 - val_recall_1: 0.5451 - lr: 0.0012\n",
      "Epoch 13/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.2784 - accuracy: 0.7095 - auc_2: 0.7387 - auc_3: 0.7358 - precision_1: 0.6165 - recall_1: 0.6262\n",
      "Epoch 13: saving model to modeling/log_effnet/model.13-0.56.hdf5\n",
      "613/613 [==============================] - 157s 255ms/step - loss: 0.2784 - accuracy: 0.7095 - auc_2: 0.7387 - auc_3: 0.7358 - precision_1: 0.6165 - recall_1: 0.6262 - val_loss: 0.5617 - val_accuracy: 0.7161 - val_auc_2: 0.7752 - val_auc_3: 0.7809 - val_precision_1: 0.6072 - val_recall_1: 0.7224 - lr: 0.0012\n",
      "Epoch 14/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.2731 - accuracy: 0.7119 - auc_2: 0.7455 - auc_3: 0.7449 - precision_1: 0.6202 - recall_1: 0.6293\n",
      "Epoch 14: saving model to modeling/log_effnet/model.14-0.53.hdf5\n",
      "613/613 [==============================] - 156s 255ms/step - loss: 0.2731 - accuracy: 0.7119 - auc_2: 0.7455 - auc_3: 0.7449 - precision_1: 0.6202 - recall_1: 0.6293 - val_loss: 0.5295 - val_accuracy: 0.7606 - val_auc_2: 0.7746 - val_auc_3: 0.7808 - val_precision_1: 0.6965 - val_recall_1: 0.6592 - lr: 0.0012\n",
      "Epoch 15/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.2756 - accuracy: 0.7113 - auc_2: 0.7410 - auc_3: 0.7403 - precision_1: 0.6199 - recall_1: 0.6247\n",
      "Epoch 15: saving model to modeling/log_effnet/model.15-0.52.hdf5\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "613/613 [==============================] - 157s 255ms/step - loss: 0.2756 - accuracy: 0.7113 - auc_2: 0.7410 - auc_3: 0.7403 - precision_1: 0.6199 - recall_1: 0.6247 - val_loss: 0.5167 - val_accuracy: 0.7782 - val_auc_2: 0.7749 - val_auc_3: 0.7809 - val_precision_1: 0.7526 - val_recall_1: 0.6227 - lr: 0.0012\n",
      "Epoch 16/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.2686 - accuracy: 0.7233 - auc_2: 0.7493 - auc_3: 0.7505 - precision_1: 0.6395 - recall_1: 0.6287\n",
      "Epoch 16: saving model to modeling/log_effnet/model.16-0.53.hdf5\n",
      "613/613 [==============================] - 158s 258ms/step - loss: 0.2686 - accuracy: 0.7233 - auc_2: 0.7493 - auc_3: 0.7505 - precision_1: 0.6395 - recall_1: 0.6287 - val_loss: 0.5274 - val_accuracy: 0.7659 - val_auc_2: 0.7738 - val_auc_3: 0.7794 - val_precision_1: 0.7121 - val_recall_1: 0.6455 - lr: 6.2500e-04\n",
      "Epoch 17/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.2695 - accuracy: 0.7188 - auc_2: 0.7493 - auc_3: 0.7482 - precision_1: 0.6307 - recall_1: 0.6316\n",
      "Epoch 17: saving model to modeling/log_effnet/model.17-0.51.hdf5\n",
      "613/613 [==============================] - 168s 273ms/step - loss: 0.2695 - accuracy: 0.7188 - auc_2: 0.7493 - auc_3: 0.7482 - precision_1: 0.6307 - recall_1: 0.6316 - val_loss: 0.5053 - val_accuracy: 0.7806 - val_auc_2: 0.7749 - val_auc_3: 0.7810 - val_precision_1: 0.8603 - val_recall_1: 0.5075 - lr: 6.2500e-04\n",
      "Epoch 18/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.2690 - accuracy: 0.7196 - auc_2: 0.7476 - auc_3: 0.7480 - precision_1: 0.6331 - recall_1: 0.6280\n",
      "Epoch 18: saving model to modeling/log_effnet/model.18-0.52.hdf5\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "613/613 [==============================] - 163s 265ms/step - loss: 0.2690 - accuracy: 0.7196 - auc_2: 0.7476 - auc_3: 0.7480 - precision_1: 0.6331 - recall_1: 0.6280 - val_loss: 0.5193 - val_accuracy: 0.7766 - val_auc_2: 0.7749 - val_auc_3: 0.7808 - val_precision_1: 0.7468 - val_recall_1: 0.6278 - lr: 6.2500e-04\n",
      "Epoch 19/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.2613 - accuracy: 0.7331 - auc_2: 0.7602 - auc_3: 0.7618 - precision_1: 0.6575 - recall_1: 0.6256\n",
      "Epoch 19: saving model to modeling/log_effnet/model.19-0.51.hdf5\n",
      "613/613 [==============================] - 162s 264ms/step - loss: 0.2613 - accuracy: 0.7331 - auc_2: 0.7602 - auc_3: 0.7618 - precision_1: 0.6575 - recall_1: 0.6256 - val_loss: 0.5069 - val_accuracy: 0.7819 - val_auc_2: 0.7743 - val_auc_3: 0.7795 - val_precision_1: 0.8163 - val_recall_1: 0.5495 - lr: 3.1250e-04\n",
      "Epoch 20/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.2632 - accuracy: 0.7313 - auc_2: 0.7546 - auc_3: 0.7573 - precision_1: 0.6564 - recall_1: 0.6183\n",
      "Epoch 20: saving model to modeling/log_effnet/model.20-0.57.hdf5\n",
      "613/613 [==============================] - 161s 262ms/step - loss: 0.2632 - accuracy: 0.7313 - auc_2: 0.7546 - auc_3: 0.7573 - precision_1: 0.6564 - recall_1: 0.6183 - val_loss: 0.5687 - val_accuracy: 0.7075 - val_auc_2: 0.7748 - val_auc_3: 0.7807 - val_precision_1: 0.5938 - val_recall_1: 0.7363 - lr: 3.1250e-04\n",
      "Epoch 21/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.2624 - accuracy: 0.7372 - auc_2: 0.7601 - auc_3: 0.7612 - precision_1: 0.6592 - recall_1: 0.6414\n",
      "Epoch 21: saving model to modeling/log_effnet/model.21-0.53.hdf5\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "613/613 [==============================] - 153s 248ms/step - loss: 0.2624 - accuracy: 0.7372 - auc_2: 0.7601 - auc_3: 0.7612 - precision_1: 0.6592 - recall_1: 0.6414 - val_loss: 0.5275 - val_accuracy: 0.7667 - val_auc_2: 0.7751 - val_auc_3: 0.7805 - val_precision_1: 0.7103 - val_recall_1: 0.6531 - lr: 3.1250e-04\n",
      "Epoch 22/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.2596 - accuracy: 0.7446 - auc_2: 0.7598 - auc_3: 0.7653 - precision_1: 0.6799 - recall_1: 0.6228\n",
      "Epoch 22: saving model to modeling/log_effnet/model.22-0.56.hdf5\n",
      "613/613 [==============================] - 152s 248ms/step - loss: 0.2596 - accuracy: 0.7446 - auc_2: 0.7598 - auc_3: 0.7653 - precision_1: 0.6799 - recall_1: 0.6228 - val_loss: 0.5620 - val_accuracy: 0.7161 - val_auc_2: 0.7746 - val_auc_3: 0.7804 - val_precision_1: 0.6074 - val_recall_1: 0.7213 - lr: 1.5625e-04\n",
      "Epoch 23/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.2590 - accuracy: 0.7408 - auc_2: 0.7633 - auc_3: 0.7652 - precision_1: 0.6723 - recall_1: 0.6230\n",
      "Epoch 23: saving model to modeling/log_effnet/model.23-0.51.hdf5\n",
      "613/613 [==============================] - 152s 248ms/step - loss: 0.2590 - accuracy: 0.7408 - auc_2: 0.7633 - auc_3: 0.7652 - precision_1: 0.6723 - recall_1: 0.6230 - val_loss: 0.5131 - val_accuracy: 0.7770 - val_auc_2: 0.7741 - val_auc_3: 0.7797 - val_precision_1: 0.7696 - val_recall_1: 0.5912 - lr: 1.5625e-04\n",
      "Epoch 24/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.2591 - accuracy: 0.7422 - auc_2: 0.7648 - auc_3: 0.7686 - precision_1: 0.6698 - recall_1: 0.6378\n",
      "Epoch 24: saving model to modeling/log_effnet/model.24-0.51.hdf5\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "613/613 [==============================] - 152s 248ms/step - loss: 0.2591 - accuracy: 0.7422 - auc_2: 0.7648 - auc_3: 0.7686 - precision_1: 0.6698 - recall_1: 0.6378 - val_loss: 0.5100 - val_accuracy: 0.7770 - val_auc_2: 0.7759 - val_auc_3: 0.7818 - val_precision_1: 0.7803 - val_recall_1: 0.5782 - lr: 1.5625e-04\n",
      "Epoch 25/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.2578 - accuracy: 0.7493 - auc_2: 0.7644 - auc_3: 0.7684 - precision_1: 0.6894 - recall_1: 0.6230\n",
      "Epoch 25: saving model to modeling/log_effnet/model.25-0.54.hdf5\n",
      "613/613 [==============================] - 151s 246ms/step - loss: 0.2578 - accuracy: 0.7493 - auc_2: 0.7644 - auc_3: 0.7684 - precision_1: 0.6894 - recall_1: 0.6230 - val_loss: 0.5367 - val_accuracy: 0.7504 - val_auc_2: 0.7759 - val_auc_3: 0.7807 - val_precision_1: 0.6717 - val_recall_1: 0.6724 - lr: 7.8125e-05\n",
      "Epoch 26/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.2585 - accuracy: 0.7446 - auc_2: 0.7630 - auc_3: 0.7683 - precision_1: 0.6807 - recall_1: 0.6201\n",
      "Epoch 26: saving model to modeling/log_effnet/model.26-0.53.hdf5\n",
      "613/613 [==============================] - 152s 247ms/step - loss: 0.2585 - accuracy: 0.7446 - auc_2: 0.7630 - auc_3: 0.7683 - precision_1: 0.6807 - recall_1: 0.6201 - val_loss: 0.5294 - val_accuracy: 0.7610 - val_auc_2: 0.7752 - val_auc_3: 0.7820 - val_precision_1: 0.6976 - val_recall_1: 0.6595 - lr: 7.8125e-05\n",
      "Epoch 27/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.2589 - accuracy: 0.7409 - auc_2: 0.7645 - auc_3: 0.7681 - precision_1: 0.6694 - recall_1: 0.6323\n",
      "Epoch 27: saving model to modeling/log_effnet/model.27-0.61.hdf5\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "613/613 [==============================] - 153s 249ms/step - loss: 0.2589 - accuracy: 0.7409 - auc_2: 0.7645 - auc_3: 0.7681 - precision_1: 0.6694 - recall_1: 0.6323 - val_loss: 0.6065 - val_accuracy: 0.6426 - val_auc_2: 0.7752 - val_auc_3: 0.7814 - val_precision_1: 0.5213 - val_recall_1: 0.7840 - lr: 7.8125e-05\n",
      "Epoch 28/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.2579 - accuracy: 0.7426 - auc_2: 0.7636 - auc_3: 0.7694 - precision_1: 0.6749 - recall_1: 0.6262\n",
      "Epoch 28: saving model to modeling/log_effnet/model.28-0.53.hdf5\n",
      "613/613 [==============================] - 153s 249ms/step - loss: 0.2579 - accuracy: 0.7426 - auc_2: 0.7636 - auc_3: 0.7694 - precision_1: 0.6749 - recall_1: 0.6262 - val_loss: 0.5298 - val_accuracy: 0.7614 - val_auc_2: 0.7743 - val_auc_3: 0.7797 - val_precision_1: 0.6997 - val_recall_1: 0.6531 - lr: 3.9062e-05\n",
      "Epoch 29/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.2572 - accuracy: 0.7495 - auc_2: 0.7658 - auc_3: 0.7709 - precision_1: 0.6908 - recall_1: 0.6206\n",
      "Epoch 29: saving model to modeling/log_effnet/model.29-0.54.hdf5\n",
      "613/613 [==============================] - 155s 252ms/step - loss: 0.2572 - accuracy: 0.7495 - auc_2: 0.7658 - auc_3: 0.7709 - precision_1: 0.6908 - recall_1: 0.6206 - val_loss: 0.5392 - val_accuracy: 0.7475 - val_auc_2: 0.7752 - val_auc_3: 0.7810 - val_precision_1: 0.6653 - val_recall_1: 0.6781 - lr: 3.9062e-05\n",
      "Epoch 30/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.2570 - accuracy: 0.7489 - auc_2: 0.7664 - auc_3: 0.7720 - precision_1: 0.6857 - recall_1: 0.6292\n",
      "Epoch 30: saving model to modeling/log_effnet/model.30-0.55.hdf5\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "613/613 [==============================] - 152s 248ms/step - loss: 0.2570 - accuracy: 0.7489 - auc_2: 0.7664 - auc_3: 0.7720 - precision_1: 0.6857 - recall_1: 0.6292 - val_loss: 0.5462 - val_accuracy: 0.7414 - val_auc_2: 0.7746 - val_auc_3: 0.7810 - val_precision_1: 0.6510 - val_recall_1: 0.6963 - lr: 3.9062e-05\n",
      "Epoch 31/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.2584 - accuracy: 0.7446 - auc_2: 0.7637 - auc_3: 0.7691 - precision_1: 0.6785 - recall_1: 0.6265\n",
      "Epoch 31: saving model to modeling/log_effnet/model.31-0.54.hdf5\n",
      "613/613 [==============================] - 152s 248ms/step - loss: 0.2584 - accuracy: 0.7446 - auc_2: 0.7637 - auc_3: 0.7691 - precision_1: 0.6785 - recall_1: 0.6265 - val_loss: 0.5369 - val_accuracy: 0.7512 - val_auc_2: 0.7751 - val_auc_3: 0.7813 - val_precision_1: 0.6738 - val_recall_1: 0.6731 - lr: 1.9531e-05\n",
      "Epoch 32/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.2578 - accuracy: 0.7444 - auc_2: 0.7646 - auc_3: 0.7693 - precision_1: 0.6783 - recall_1: 0.6267\n",
      "Epoch 32: saving model to modeling/log_effnet/model.32-0.54.hdf5\n",
      "613/613 [==============================] - 152s 248ms/step - loss: 0.2578 - accuracy: 0.7444 - auc_2: 0.7646 - auc_3: 0.7693 - precision_1: 0.6783 - recall_1: 0.6267 - val_loss: 0.5432 - val_accuracy: 0.7451 - val_auc_2: 0.7745 - val_auc_3: 0.7804 - val_precision_1: 0.6585 - val_recall_1: 0.6881 - lr: 1.9531e-05\n",
      "Epoch 33/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.2564 - accuracy: 0.7454 - auc_2: 0.7688 - auc_3: 0.7729 - precision_1: 0.6785 - recall_1: 0.6304\n",
      "Epoch 33: saving model to modeling/log_effnet/model.33-0.53.hdf5\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "613/613 [==============================] - 152s 247ms/step - loss: 0.2564 - accuracy: 0.7454 - auc_2: 0.7688 - auc_3: 0.7729 - precision_1: 0.6785 - recall_1: 0.6304 - val_loss: 0.5292 - val_accuracy: 0.7618 - val_auc_2: 0.7749 - val_auc_3: 0.7814 - val_precision_1: 0.7026 - val_recall_1: 0.6538 - lr: 1.9531e-05\n",
      "Epoch 34/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.2582 - accuracy: 0.7444 - auc_2: 0.7650 - auc_3: 0.7702 - precision_1: 0.6745 - recall_1: 0.6366\n",
      "Epoch 34: saving model to modeling/log_effnet/model.34-0.53.hdf5\n",
      "613/613 [==============================] - 153s 249ms/step - loss: 0.2582 - accuracy: 0.7444 - auc_2: 0.7650 - auc_3: 0.7702 - precision_1: 0.6745 - recall_1: 0.6366 - val_loss: 0.5307 - val_accuracy: 0.7610 - val_auc_2: 0.7749 - val_auc_3: 0.7812 - val_precision_1: 0.6980 - val_recall_1: 0.6599 - lr: 1.0000e-05\n",
      "Epoch 35/50\n",
      "613/613 [==============================] - ETA: 0s - loss: 0.2581 - accuracy: 0.7468 - auc_2: 0.7652 - auc_3: 0.7700 - precision_1: 0.6822 - recall_1: 0.6276\n",
      "Epoch 35: saving model to modeling/log_effnet/model.35-0.53.hdf5\n",
      "613/613 [==============================] - 238s 388ms/step - loss: 0.2581 - accuracy: 0.7468 - auc_2: 0.7652 - auc_3: 0.7700 - precision_1: 0.6822 - recall_1: 0.6276 - val_loss: 0.5263 - val_accuracy: 0.7680 - val_auc_2: 0.7756 - val_auc_3: 0.7816 - val_precision_1: 0.7165 - val_recall_1: 0.6474 - lr: 1.0000e-05\n",
      "Epoch 36/50\n",
      "383/613 [=================>............] - ETA: 46s - loss: 0.2540 - accuracy: 0.7573 - auc_2: 0.7734 - auc_3: 0.7729 - precision_1: 0.6978 - recall_1: 0.6260"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# train model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit_generator(generator \u001b[39m=\u001b[39;49m train_generator,\n\u001b[1;32m      3\u001b[0m                               steps_per_epoch \u001b[39m=\u001b[39;49m STEP_SIZE_TRAIN,\n\u001b[1;32m      4\u001b[0m                               validation_data \u001b[39m=\u001b[39;49m val_generator,\n\u001b[1;32m      5\u001b[0m                               validation_steps \u001b[39m=\u001b[39;49m STEP_SIZE_VALID,\n\u001b[1;32m      6\u001b[0m                               epochs \u001b[39m=\u001b[39;49m \u001b[39m50\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m                               class_weight \u001b[39m=\u001b[39;49m class_weights,\n\u001b[1;32m      8\u001b[0m                               callbacks \u001b[39m=\u001b[39;49m [mcp_save, lr_reduction, csv_logger])\n",
      "File \u001b[0;32m~/anaconda3/envs/mlp-env/lib/python3.8/site-packages/keras/src/engine/training.py:2810\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2798\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[1;32m   2799\u001b[0m \n\u001b[1;32m   2800\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[1;32m   2801\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[1;32m   2802\u001b[0m \u001b[39m  use this endpoint.\u001b[39;00m\n\u001b[1;32m   2803\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2804\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   2805\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2806\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2807\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2808\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m   2809\u001b[0m )\n\u001b[0;32m-> 2810\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m   2811\u001b[0m     generator,\n\u001b[1;32m   2812\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   2813\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m   2814\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2815\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   2816\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[1;32m   2817\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   2818\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[1;32m   2819\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[1;32m   2820\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   2821\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   2822\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   2823\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   2824\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[1;32m   2825\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/mlp-env/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlp-env/lib/python3.8/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/mlp-env/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlp-env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlp-env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/mlp-env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlp-env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/mlp-env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/anaconda3/envs/mlp-env/lib/python3.8/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/mlp-env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train model\n",
    "history = model.fit_generator(generator = train_generator,\n",
    "                              steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "                              validation_data = val_generator,\n",
    "                              validation_steps = STEP_SIZE_VALID,\n",
    "                              epochs = 50,\n",
    "                              class_weight = class_weights,\n",
    "                              callbacks = [mcp_save, lr_reduction, csv_logger])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
